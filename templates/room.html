<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Meeting: {{ meeting_id }}</title>
  <link
    rel="stylesheet"
    href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/css/bootstrap.min.css"
  />
  <style>
    body {
      background-color: #242424;
      color: #fff;
      margin: 0;
      overflow: hidden;
      transition: all 0.5s ease; /* Smooth transition for swapping */
    }
    /* Top toolbar */
    #topToolbar {
      position: fixed;
      top: 0;
      left: 0;
      width: 100%;
      height: 60px;
      background: rgba(0, 0, 0, 0.8);
      z-index: 10;
      display: flex;
      align-items: center;
      justify-content: space-between;
      padding: 0 20px;
    }
    #topToolbar h2 {
      margin: 0;
      font-size: 1.25rem;
      color: #fff;
    }

    /* Remote video container */
    #remoteContainer {
      position: fixed;
      top: 60px;
      left: 0;
      width: 100vw;
      height: calc(100vh - 60px);
      background: #000;
      z-index: 0;
      overflow: hidden;
      transition: all 0.5s ease; /* Smooth transition for swapping */
    }
    #remoteVideo {
      width: 100%;
      height: 100%;
      object-fit: cover;
    }

    /* Placeholder for remote video when not visible */
    #remotePlaceholder {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      background-color: #000;
      display: flex;
      align-items: center;
      justify-content: center;
      z-index: 1;
      display: flex; /* Initially display the placeholder */
    }
    /* SVG Icon Styling */
    #remotePlaceholder svg {
      width: 100px;
      height: 100px;
      fill: #555;
    }

    /* Local video in bottom-right corner */
    #localContainer {
      position: fixed;
      bottom: 20px;
      right: 20px;
      width: 320px;
      height: 240px;
      background: #000;
      border: 2px solid #333;
      border-radius: 8px;
      z-index: 2;
      overflow: hidden;
      transition: all 0.5s ease; /* Smooth transition for swapping */
    }
    #localVideo {
      width: 100%;
      height: 100%;
      object-fit: cover;
    }

    /* Canvas for PoseNet */
    #keypointCanvas {
      position: absolute;
      top: 0;
      left: 0;
      pointer-events: none;
      z-index: 3;
    }

    /* Overlays */
    #signOverlay {
      position: fixed;
      bottom: 80px;
      left: 50%;
      transform: translateX(-50%);
      max-width: 80%;
      background: rgba(0, 0, 0, 0.5);
      color: #fff;
      padding: 10px 20px;
      border-radius: 10px;
      text-align: center;
      font-size: 1.2rem;
      white-space: pre-wrap;
      z-index: 4;
      display: none;
      text-shadow: 2px 2px 4px #000;
    }
    #sentenceOverlay {
      position: fixed;
      bottom: 140px;
      left: 50%;
      transform: translateX(-50%);
      max-width: 80%;
      background: rgba(0, 0, 0, 0.7);
      color: #fff;
      padding: 10px 20px;
      border-radius: 10px;
      text-align: center;
      font-size: 1.2rem;
      white-space: pre-wrap;
      z-index: 5;
      display: none;
      text-shadow: 2px 2px 4px #000;
    }
    #errorMessages {
      position: fixed;
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%);
      z-index: 11;
      background: rgba(255, 0, 0, 0.9);
      color: white;
      padding: 20px;
      border-radius: 10px;
      display: none;
    }

    #statusIndicator {
      color: #0f0;
      font-size: 0.9rem;
    }
    #toolbarControls button {
      margin-left: 10px;
    }

    /* Swapped State Styles */
    body.swapped #remoteContainer {
      top: auto;
      left: auto;
      bottom: 20px;
      right: 20px;
      width: 320px;
      height: 240px;
      z-index: 3; /* Bring to front */
    }

    body.swapped #localContainer {
      top: 60px;
      left: 0;
      bottom: auto;
      right: auto;
      width: 100vw;
      height: calc(100vh - 60px);
      z-index: 2; /* Below remoteContainer */
    }

    /* Ensure smooth transitions when swapping */
    body.swapped #remoteContainer,
    body.swapped #localContainer {
      transition: all 0.5s ease;
    }
  </style>
</head>
<body>
  <!-- Top Toolbar -->
  <div id="topToolbar">
    <h2>Meeting: {{ meeting_id }}</h2>
    <div id="statusIndicator">Status: Initializing...</div>
    <div id="toolbarControls">
      <button id="toggleVideo" class="btn btn-warning btn-sm">Toggle Video</button>
      <button id="toggleAudio" class="btn btn-warning btn-sm">Toggle Audio</button>
      <button id="toggleSignLanguageBtn" class="btn btn-primary btn-sm">Enable Sign Language</button>
      <button id="toggleTTSBtn" class="btn btn-secondary btn-sm">Enable TTS</button>
      <button id="leaveBtn" class="btn btn-danger btn-sm">Leave</button>
    </div>
  </div>

  <!-- Remote video -->
  <div id="remoteContainer">
    <video id="remoteVideo" autoplay playsinline></video>
    <!-- Placeholder for when remote video is not visible -->
    <div id="remotePlaceholder">
      <!-- Example SVG Placeholder: A simple person icon -->
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 64 64">
        <circle cx="32" cy="30" r="12" stroke="#555" stroke-width="2" fill="none"/>
        <path d="M16,60 C16,40 48,40 48,60" stroke="#555" stroke-width="2" fill="none"/>
        <path d="M16,60 C16,40 48,40 48,60" stroke="#555" stroke-width="2" fill="none"/>
        <line x1="16" y1="40" x2="16" y2="40" stroke="#555" stroke-width="2"/>
        <line x1="48" y1="40" x2="48" y2="40" stroke="#555" stroke-width="2"/>
      </svg>
    </div>
  </div>

  <!-- Local video + keypoint canvas -->
  <div id="localContainer">
    <video id="localVideo" autoplay muted playsinline></video>
    <canvas id="keypointCanvas"></canvas>
  </div>

  <!-- Overlays -->
  <div id="signOverlay"></div>
  <div id="sentenceOverlay"></div>
  <div id="errorMessages"></div>

  <!-- Scripts: TensorFlow.js & PoseNet & Socket.IO -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.20.0/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/posenet@2.2.1/dist/posenet.min.js"></script>
  <script src="https://cdn.socket.io/4.6.1/socket.io.min.js"></script>
  
  <!-- Combined Script for TTS and Voice Selection -->
  <script>
    /*****************************************************
     * GLOBALS & DOM REFERENCES
     *****************************************************/
    const MEETING_ID = "{{ meeting_id }}";
    const statusIndicator = document.getElementById("statusIndicator");
    const errorMessages = document.getElementById("errorMessages");
    const signOverlay = document.getElementById("signOverlay");
    const sentenceOverlay = document.getElementById("sentenceOverlay");

    const localVideo = document.getElementById("localVideo");
    const remoteVideo = document.getElementById("remoteVideo");
    const remotePlaceholder = document.getElementById("remotePlaceholder"); // Added
    const keypointCanvas = document.getElementById("keypointCanvas");
    const keypointCtx = keypointCanvas.getContext("2d");

    // WebRTC + Socket
    const socket = io();
    let localStream;
    let peerConnection;
    let posenetModel;

    // Flags
    let usingSignLanguage = false;
    let frameTimer = null;
    let ttsEnabled = false;

    // Selected male voice
    let selectedMaleVoice = null;

    /*****************************************************
     * ERROR + STATUS HELPERS
     *****************************************************/
    function showError(message, timeout = 5000) {
      console.error(message);
      errorMessages.textContent = message;
      errorMessages.style.display = "block";
      if (timeout) {
        setTimeout(() => {
          errorMessages.style.display = "none";
        }, timeout);
      }
    }

    function updateStatus(msg) {
      console.log(msg);
      statusIndicator.textContent = `Status: ${msg}`;
    }

    /*****************************************************
     * MEDIA + PoseNet SETUP
     *****************************************************/
    async function setupLocalMedia() {
      try {
        updateStatus("Requesting camera/mic access...");
        localStream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });
        localVideo.srcObject = localStream;
        updateStatus("Local media connected");

        socket.emit("join", { meeting_id: MEETING_ID });

        // Wait a moment for video to have a size
        localVideo.onloadedmetadata = async () => {
          console.log("Local video metadata loaded.", localVideo.videoWidth, localVideo.videoHeight);
          await loadPoseNet();
        };
      } catch (err) {
        showError(`Media access error: ${err.message}`, 0);
      }
    }

    async function loadPoseNet() {
      try {
        updateStatus("Loading PoseNet...");
        posenetModel = await posenet.load({
          architecture: "MobileNetV1",
          outputStride: 16,
          inputResolution: { width: 640, height: 480 },
          multiplier: 0.75
        });
        updateStatus("PoseNet loaded successfully");
        startPoseDetectionLoop();
      } catch (err) {
        showError(`PoseNet loading error: ${err.message}`, 0);
      }
    }

    function startPoseDetectionLoop() {
      // Resize canvas to match actual video resolution
      keypointCanvas.width = localVideo.videoWidth;
      keypointCanvas.height = localVideo.videoHeight;
      keypointCanvas.style.width = `${localVideo.clientWidth}px`;
      keypointCanvas.style.height = `${localVideo.clientHeight}px`;
      console.log("Canvas:", keypointCanvas.width, keypointCanvas.height);

      async function poseDetectFrame() {
        if (localVideo.readyState === localVideo.HAVE_ENOUGH_DATA && posenetModel) {
          const pose = await posenetModel.estimateSinglePose(localVideo, {
            flipHorizontal: true
          });

          keypointCtx.clearRect(0, 0, keypointCanvas.width, keypointCanvas.height);
          drawKeypoints(pose.keypoints, 0.5);
          drawSkeleton(pose.keypoints, 0.5);
        }
        requestAnimationFrame(poseDetectFrame);
      }
      poseDetectFrame();
    }

    function drawKeypoints(keypoints, minConfidence) {
      keypoints.forEach(({ position: { x, y }, score }) => {
        if (score >= minConfidence) {
          keypointCtx.beginPath();
          keypointCtx.arc(x, y, 5, 0, 2 * Math.PI);
          keypointCtx.fillStyle = "aqua";
          keypointCtx.fill();
        }
      });
    }

    function drawSkeleton(keypoints, minConfidence) {
      const adjacentKeyPoints = posenet.getAdjacentKeyPoints(keypoints, minConfidence);
      adjacentKeyPoints.forEach(([from, to]) => {
        keypointCtx.beginPath();
        keypointCtx.moveTo(from.position.x, from.position.y);
        keypointCtx.lineTo(to.position.x, to.position.y);
        keypointCtx.strokeStyle = "lime";
        keypointCtx.lineWidth = 2;
        keypointCtx.stroke();
      });
    }

    /*****************************************************
     * SENDING FRAMES TO SERVER (VIDEO_FRAME EVENT)
     *****************************************************/
    function startSendingFramesToServer() {
      const FPS = 25;
      frameTimer = setInterval(() => {
        if (!usingSignLanguage) return;
        if (!localVideo || localVideo.readyState < 2) return;

        const offscreen = document.createElement("canvas");
        offscreen.width = 320;
        offscreen.height = 240;
        const ctx = offscreen.getContext("2d");
        ctx.drawImage(localVideo, 0, 0, offscreen.width, offscreen.height);

        const base64Data = offscreen.toDataURL("image/jpeg", 0.5);
        socket.emit("video_frame", {
          data: base64Data,
          meeting_id: MEETING_ID
        });
      }, 1000 / FPS);
      console.log("Started sending frames to server.");
    }

    function stopSendingFramesToServer() {
      if (frameTimer) clearInterval(frameTimer);
      frameTimer = null;
      console.log("Stopped sending frames to server.");
    }

    /*****************************************************
     * WEBRTC PEER CONNECTION
     *****************************************************/
    const iceConfig = {
      iceServers: [
        { urls: "stun:stun.l.google.com:19302" }
        {% if turn_url and turn_username and turn_credential %}
        , {
          urls: "{{ turn_url }}",
          username: "{{ turn_username }}",
          credential: "{{ turn_credential }}"
        }
        {% endif %}
      ]
    };

    function createPeerConnection() {
      try {
        peerConnection = new RTCPeerConnection(iceConfig);

        peerConnection.onicecandidate = (e) => {
          if (e.candidate) {
            socket.emit("signal", {
              meeting_id: MEETING_ID,
              signal: { candidate: e.candidate }
            });
          }
        };

        peerConnection.oniceconnectionstatechange = () => {
          const state = peerConnection.iceConnectionState;
          updateStatus(`ICE Connection: ${state}`);
          if (["disconnected", "failed", "closed"].includes(state)) {
            remoteVideo.srcObject = null;
            showRemotePlaceholder(); // Show placeholder when disconnected
            if (state === "failed") {
              showError("Connection failed. Try refreshing the page.");
            }
          }
        };

        peerConnection.ontrack = (event) => {
          if (event.streams && event.streams[0]) {
            remoteVideo.srcObject = event.streams[0];
            updateStatus("Remote video connected");
            // Hide placeholder when remote video is connected
            hideRemotePlaceholder();
          }
        };

        return true;
      } catch (err) {
        showError(`Failed to create peer connection: ${err.message}`);
        return false;
      }
    }

    /*****************************************************
     * SOCKET.IO HANDLERS
     *****************************************************/
    socket.on("connect", () => {
      updateStatus("Socket Connected");
    });

    socket.on("connect_error", (err) => {
      showError(`Socket connection error: ${err.message}`);
    });

    socket.on("user_joined", (data) => {
      console.log("User joined:", data);
      updateStatus("Peer joined - Creating connection...");
      if (!peerConnection && createPeerConnection()) {
        localStream.getTracks().forEach((track) => {
          peerConnection.addTrack(track, localStream);
        });
        peerConnection
          .createOffer()
          .then((offer) => peerConnection.setLocalDescription(offer))
          .then(() => {
            socket.emit("signal", {
              meeting_id: MEETING_ID,
              signal: { sdp: peerConnection.localDescription }
            });
          })
          .catch((err) => {
            showError(`Failed to create offer: ${err.message}`);
          });
      }
    });

    socket.on("signal", async (data) => {
      try {
        if (data.sdp) {
          await handleSDP(data.sdp);
        } else if (data.candidate) {
          await handleCandidate(data.candidate);
        }
      } catch (err) {
        showError(`Signaling error: ${err.message}`);
      }
    });

    async function handleSDP(sdp) {
      if (!peerConnection) {
        if (!createPeerConnection()) return;
        localStream.getTracks().forEach((track) => {
          peerConnection.addTrack(track, localStream);
        });
      }
      await peerConnection.setRemoteDescription(new RTCSessionDescription(sdp));
      if (sdp.type === "offer") {
        const answer = await peerConnection.createAnswer();
        await peerConnection.setLocalDescription(answer);
        socket.emit("signal", {
          meeting_id: MEETING_ID,
          signal: { sdp: peerConnection.localDescription }
        });
      }
    }

    async function handleCandidate(candidate) {
      if (peerConnection) {
        await peerConnection.addIceCandidate(new RTCIceCandidate(candidate));
      }
    }

    // Recognized signs from the server
    socket.on("recognized_sign", (data) => {
      // Example: data => { sign: "...", sentence: "...", user_sid: "..." }
      console.log("recognized_sign:", data);
      if (data.sign) {
        signOverlay.textContent = data.sign;
        signOverlay.style.display = "block";
        setTimeout(() => {
          signOverlay.style.display = "none";
        }, 3000);
      }
      if (data.sentence) {
        sentenceOverlay.textContent = data.sentence;
        sentenceOverlay.style.display = "block";
        setTimeout(() => {
          sentenceOverlay.style.display = "none";
        }, 3000);
      }
      if (ttsEnabled) {
        if (data.sentence) speakText(data.sentence);
        else if (data.sign) speakText(data.sign);
      }
    });

    socket.on("sign_language_status", (data) => {
      console.log("sign_language_status:", data);
    });

    /*****************************************************
     * BUTTON HANDLERS
     *****************************************************/
    document.getElementById("leaveBtn").addEventListener("click", () => {
      if (localStream) localStream.getTracks().forEach((track) => track.stop());
      if (peerConnection) peerConnection.close();
      socket.disconnect();
      window.location.href = "/";
    });

    document.getElementById("toggleVideo").addEventListener("click", () => {
      const videoTrack = localStream?.getVideoTracks?.()[0];
      if (videoTrack) {
        videoTrack.enabled = !videoTrack.enabled;
        const btn = document.getElementById("toggleVideo");
        btn.textContent = videoTrack.enabled ? "Disable Video" : "Enable Video";
      }
    });

    document.getElementById("toggleAudio").addEventListener("click", () => {
      const audioTrack = localStream?.getAudioTracks?.()[0];
      if (audioTrack) {
        audioTrack.enabled = !audioTrack.enabled;
        const btn = document.getElementById("toggleAudio");
        btn.textContent = audioTrack.enabled ? "Disable Audio" : "Enable Audio";
      }
    });

    document.getElementById("toggleSignLanguageBtn").addEventListener("click", () => {
      usingSignLanguage = !usingSignLanguage;
      socket.emit("toggle_sign_language", {
        enabled: usingSignLanguage,
        meeting_id: MEETING_ID
      });
      const btn = document.getElementById("toggleSignLanguageBtn");
      btn.textContent = usingSignLanguage ? "Disable Sign Language" : "Enable Sign Language";

      if (usingSignLanguage) {
        startSendingFramesToServer();
      } else {
        stopSendingFramesToServer();
        signOverlay.style.display = "none";
        sentenceOverlay.style.display = "none";
      }
    });

    const toggleTTSBtn = document.getElementById("toggleTTSBtn");
    toggleTTSBtn.addEventListener("click", () => {
      ttsEnabled = !ttsEnabled;
      toggleTTSBtn.textContent = ttsEnabled ? "Disable TTS" : "Enable TTS";
      if (ttsEnabled) speakText("Text to speech is now enabled.");
    });

    /*****************************************************
     * BROWSER SPEECH SYNTHESIS WITH MALE VOICE
     *****************************************************/
    function logAvailableVoices() {
      const voices = speechSynthesis.getVoices();
      console.log("Available Voices:");
      voices.forEach((voice, index) => {
        console.log(`${index + 1}. Name: ${voice.name}, Lang: ${voice.lang}`);
      });
    }

    function selectMaleVoice() {
      const voices = speechSynthesis.getVoices();

      // List of known male voice names (adjust based on your console logs)
      const maleVoiceNames = [
        'Google US English', // Common in Chrome
        'Microsoft David Desktop - English (United States)', // Common in Windows
        'Alex', // macOS
        // Add more male voice names as needed
      ];

      // Find the first matching male voice
      selectedMaleVoice = voices.find(voice => maleVoiceNames.includes(voice.name));

      // Fallback if no male voice is found
      if (!selectedMaleVoice && voices.length > 0) {
        selectedMaleVoice = voices[0];
        console.warn('No male voice found. Falling back to the default voice:', selectedMaleVoice.name);
      } else if (!selectedMaleVoice) {
        console.error('No voices available for speech synthesis.');
      }
    }

    // Initialize voice selection
    if (speechSynthesis.onvoiceschanged !== undefined) {
      speechSynthesis.onvoiceschanged = () => {
        selectMaleVoice();
        logAvailableVoices(); // Optional: Log voices after selection
      };
    } else {
      selectMaleVoice();
      logAvailableVoices(); // Optional: Log voices after selection
    }

    // Modified speakText function using the selected male voice
    function speakText(text) {
      if ("speechSynthesis" in window) {
        if (speechSynthesis.speaking) {
          console.log("Speech synthesis already in progress. Queuing the utterance.");
        }

        console.log("Speaking:", text);
        const utterance = new SpeechSynthesisUtterance(text);
        utterance.lang = "en-US";
        
        if (selectedMaleVoice) {
          utterance.voice = selectedMaleVoice;
        } else {
          console.warn('No male voice selected. Using the default voice.');
        }
        
        utterance.pitch = 1; // Adjusted from 0.05 to 1 for better audibility
        utterance.rate = 1;  // Adjust rate as needed (0.1 to 10)
        
        speechSynthesis.speak(utterance);
      } else {
        console.warn("speechSynthesis not supported in this browser.");
      }
    }

    /*****************************************************
     * REMOTE VIDEO PLACEHOLDER HANDLERS
     *****************************************************/
    function showRemotePlaceholder() {
      remotePlaceholder.style.display = "flex";
    }

    function hideRemotePlaceholder() {
      remotePlaceholder.style.display = "none";
    }

    // Event listeners to toggle placeholder based on remote video state
    remoteVideo.addEventListener('playing', () => {
      hideRemotePlaceholder();
    });

    remoteVideo.addEventListener('pause', () => {
      showRemotePlaceholder();
    });

    remoteVideo.addEventListener('ended', () => {
      showRemotePlaceholder();
    });

    remoteVideo.addEventListener('error', () => {
      showRemotePlaceholder();
    });

    // Initially show placeholder if no remote stream is present
    socket.on("disconnect", () => {
      showRemotePlaceholder();
    });

    /*****************************************************
     * SWAP VIDEO WINDOWS ON DOUBLE-CLICK
     *****************************************************/
    function setupSwapOnDoubleClick() {
      const remoteContainer = document.getElementById("remoteContainer");
      const localContainer = document.getElementById("localContainer");

      // Function to toggle the 'swapped' class on the body
      function toggleSwap() {
        document.body.classList.toggle("swapped");
      }

      // Add double-click event listeners to both containers
      remoteContainer.addEventListener("dblclick", toggleSwap);
      localContainer.addEventListener("dblclick", toggleSwap);
    }

    /*****************************************************
     * INIT
     *****************************************************/
    setupLocalMedia();
    setupSwapOnDoubleClick(); // Initialize swap functionality
  </script>
</body>
</html>
